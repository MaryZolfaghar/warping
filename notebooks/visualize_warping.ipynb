{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize warping over training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_results(results_fn, rep_name, averaged=True):\n",
    "    \"\"\"\n",
    "        Function to load the results\n",
    "            - result_fn: the path to the result folder\n",
    "            - rep_name: what type of representation to use (e.g, the averaged representations)\n",
    "            - averaged: whether using averaged over runs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open file\n",
    "    results_dir = '../results/'\n",
    "    results_path = os.path.join(results_dir,results_fn)\n",
    "    with open(results_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    analysis = data['analysis']\n",
    "    \n",
    "    # List with all results\n",
    "    params = [[s['get_diag_vis_params'][rep_name] for s in run] for run in analysis]\n",
    "    \n",
    "    # Get useful variables (fixed across checkpoints/runs)\n",
    "    n_states = params[0][0]['n_states']\n",
    "    locs = params[0][0]['locs']\n",
    "    idx2loc = params[0][0]['idx2loc']\n",
    "    G_idxs = params[0][0]['G_idxs']\n",
    "    H_idxs = params[0][0]['H_idxs']\n",
    "    \n",
    "    # Mappings from indices to groups\n",
    "    idx2g = {}\n",
    "    for idx in range(n_states):\n",
    "        for g, group in enumerate(G_idxs):\n",
    "            if idx in group:\n",
    "                idx2g[idx] = g\n",
    "\n",
    "    idx2h = {}\n",
    "    for idx in range(n_states):\n",
    "        for h, group in enumerate(H_idxs):\n",
    "            if idx in group:\n",
    "                idx2h[idx] = h\n",
    "\n",
    "    # Get visualization parameters\n",
    "    alpha = [[p['alpha'] for p in run] for run in params]\n",
    "    beta = [[p['beta'] for p in run] for run in params]\n",
    "    alpha = np.array(alpha) # [n_runs, n_checkpoints, n_params]\n",
    "    beta = np.array(beta) # [n_runs, n_checkpoints, n_params]\n",
    "    \n",
    "    # Get congruent vs. incongruent accuracy results\n",
    "    train_results = data['results']\n",
    "    cong_accs = []\n",
    "    incong_accs = []\n",
    "    for run in train_results:\n",
    "        cong_accs.append([s['cong_acc'] for s in run['train_accs']])\n",
    "        incong_accs.append([s['incong_acc'] for s in run['train_accs']])\n",
    "    \n",
    "    # Get distance ratio results\n",
    "    ratios = []\n",
    "    for run in analysis:\n",
    "        ratios.append([s['distance_ratio'][rep_name]['ratio'] for s in run])\n",
    "    dist_ratios = np.array(ratios) # [n_runs, n_checkpoints]\n",
    "    \n",
    "    \n",
    "    # Average over runs\n",
    "    if averaged:\n",
    "        alpha = np.mean(alpha, axis=0) # [n_checkpoints, n_params]\n",
    "        beta = np.mean(beta, axis=0)   # [n_checkpoints, n_params]\n",
    "        cong_accs = np.mean(cong_accs, axis=0)\n",
    "        incong_accs = np.mean(incong_accs, axis=0)\n",
    "        acc_ratios = cong_accs/incong_accs # [n_checkpoints]\n",
    "        dist_ratios = np.mean(dist_ratios, axis=0)\n",
    "    else:\n",
    "        alpha = alpha[0] # [n_checkpoints, n_params]\n",
    "        beta = beta[0]   # [n_checkpoints, n_params]\n",
    "        cong_accs = np.array(cong_accs[0])\n",
    "        incong_accs = np.array(incong_accs[0])\n",
    "        acc_ratios = cong_accs/incong_accs # [n_checkpoints]\n",
    "        dist_ratios = dist_ratios[0] # [n_checkpoints]\n",
    "    \n",
    "    # Return results\n",
    "    results = {'n_states': n_states,\n",
    "               'locs': locs,\n",
    "               'idx2g': idx2g,\n",
    "               'idx2h': idx2h,\n",
    "               'alpha': alpha,\n",
    "               'beta': beta,\n",
    "               'cong_accs': cong_accs,\n",
    "               'incong_accs': incong_accs,\n",
    "               'acc_ratios': acc_ratios,\n",
    "               'dist_ratios': dist_ratios}\n",
    "    \n",
    "    return results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def reconstruct_grid(alpha, beta, n_states, idx2g, idx2h):\n",
    "    \"\"\"\n",
    "        Function for reconstructing grid from params:\n",
    "         - alpha: parameters for the reconstruction \n",
    "         - beta: parameters for the reconstruction \n",
    "         - n_states: number of states (i.e, 16 in the 4x4 grid)\n",
    "         - idx2g: convert index to location \n",
    "         - idx2h: convert index to location \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n_params = len(alpha)\n",
    "    \n",
    "    # Cumulative sum \n",
    "    cum_alpha = np.zeros(n_params+1)\n",
    "    cum_beta = np.zeros(n_params+1)\n",
    "    cum_alpha[1:] = np.cumsum(alpha)\n",
    "    cum_beta[1:] = np.cumsum(beta)\n",
    "    \n",
    "    # Get x and y coordinates in rotated basis\n",
    "    X = np.zeros([n_states,2])\n",
    "    for idx in range(n_states):\n",
    "        g = idx2g[idx] # G group\n",
    "        h = idx2h[idx] # H group\n",
    "        X[idx,0] = cum_alpha[g] # x coordinate\n",
    "        X[idx,1] = cum_beta[h]  # y coordinate\n",
    "        \n",
    "    # Unrotate\n",
    "    unrotate = np.array([[np.cos(-np.pi/4), -np.sin(-np.pi/4)],\n",
    "                         [np.sin(-np.pi/4), np.cos(-np.pi/4)]])\n",
    "    X = X @ unrotate\n",
    "    \n",
    "    # Mean-center\n",
    "    X = X - np.mean(X, axis=0, keepdims=True)\n",
    "    \n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def build_gif(results, model_name):\n",
    "    \"\"\"\n",
    "        Funcion for building the .gif\n",
    "            - resutls: results that inlcudes all the information\n",
    "            - model_name: name of the model\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack results\n",
    "    n_states = results['n_states']\n",
    "    locs = results['locs']\n",
    "    idx2g = results['idx2g']\n",
    "    idx2h = results['idx2h']\n",
    "    alpha = results['alpha']\n",
    "    beta = results['beta']\n",
    "    cong_accs = results['cong_accs']\n",
    "    incong_accs = results['incong_accs']\n",
    "    acc_ratios = results['acc_ratios']\n",
    "    dist_ratios = results['dist_ratios']\n",
    "    \n",
    "    # Reconstruct grid for each time point\n",
    "    n_steps = len(alpha)\n",
    "    reconstruction = np.zeros([n_steps, n_states, 2])\n",
    "    for t, (alpha_i, beta_i) in enumerate(zip(alpha,beta)):\n",
    "        X = reconstruct_grid(alpha_i, beta_i, n_states, idx2g, idx2h)\n",
    "        reconstruction[t,:,:] = X\n",
    "    \n",
    "    # Prepare to plot reconstruction\n",
    "    xmin = np.min(reconstruction[:,:,0])\n",
    "    xmax = np.max(reconstruction[:,:,0])\n",
    "    ymin = np.min(reconstruction[:,:,1])\n",
    "    ymax = np.max(reconstruction[:,:,1])\n",
    "    eps = 0.1*(np.max([xmax-xmin, ymax-ymin]))\n",
    "\n",
    "    dist_ratios_max = np.max(dist_ratios)\n",
    "    dist_ratios_min = np.min(dist_ratios)\n",
    "    acc_ratio_max = np.max(acc_ratios)\n",
    "    acc_ratio_min = np.min(acc_ratios)\n",
    "    ratio_max = np.max([dist_ratios_max, acc_ratio_max])+0.1\n",
    "    ratio_min = np.min([dist_ratios_min, acc_ratio_min])-0.1\n",
    "\n",
    "    cmap = plt.get_cmap('hot')\n",
    "    normalized_dist_ratios = [w/(dist_ratios_max+1) for w in dist_ratios]\n",
    "    colors = [cmap(nw) for nw in normalized_dist_ratios]\n",
    "    norm = Normalize(vmin=np.min(dist_ratios), \n",
    "                     vmax=np.max(dist_ratios), \n",
    "                     clip=True)\n",
    "    \n",
    "    filenames = []\n",
    "    for t,M in enumerate(reconstruction):\n",
    "        fig, ax = plt.subplots(3, 1, \n",
    "                               figsize=[8,12], \n",
    "                               gridspec_kw={'height_ratios': [1,1,3]})\n",
    "\n",
    "        # Congruent vs. incongruent accuracies over time\n",
    "        ax[0].plot(cong_accs[:t])\n",
    "        ax[0].plot(incong_accs[:t])\n",
    "        ax[0].plot(t-1, cong_accs[t-1], marker='o', c='tab:blue')\n",
    "        ax[0].plot(t-1, incong_accs[t-1], marker='o', c='tab:orange')\n",
    "        ax[0].set_title(\"Congruent vs. incongruent accuracy\")\n",
    "        ax[0].set_xlim([0,n_steps])\n",
    "        ax[0].set_ylim([-0.05,1.05])\n",
    "        ax[0].set_xlabel(\"Steps\")\n",
    "        ax[0].set_ylabel(\"Accuracy\")\n",
    "        ax[0].legend(['Congruent', 'Incongruent'], loc='lower right')\n",
    "\n",
    "        # dist_ratios vs. accuracy ratio\n",
    "        ax[1].plot(dist_ratios[:t], c='tab:green')\n",
    "        ax[1].plot(acc_ratios[:t], c='tab:purple')\n",
    "        ax[1].plot(t-1, dist_ratios[t-1], marker='o', c='tab:green')\n",
    "        ax[1].plot(t-1, acc_ratios[t-1], marker='o', c='tab:purple')\n",
    "        ax[1].set_title(\"Warping\")\n",
    "        ax[1].set_xlim([0,n_steps])\n",
    "        ax[1].set_ylim([ratio_min,ratio_max])\n",
    "        ax[1].set_xlabel(\"Steps\")\n",
    "        ax[1].set_ylabel(\"Ratio\")\n",
    "        ax[1].legend(['Distance', 'Accuracy'], loc='upper right')\n",
    "\n",
    "        # Reconstructed grid\n",
    "        scatter = ax[2].scatter(M[:,0], M[:,1], color=colors[t-1])\n",
    "        for loc,m in zip(locs,M):\n",
    "            ax[2].annotate(loc,m)\n",
    "        main_title = \"{} Representations (reconstructed)\".format(model_name.upper())\n",
    "        ax[2].set_title(main_title)\n",
    "        ax[2].set_xlim([xmin-eps, xmax+eps])\n",
    "        ax[2].set_ylim([ymin-eps, ymax+eps])\n",
    "        ax[2].set_xticks([])\n",
    "        ax[2].set_yticks([])\n",
    "        colorbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "                                ax=ax[2], aspect=40, fraction=0.03, pad=0.02)\n",
    "        colorbar.ax.set_ylabel('Warping', rotation=270, labelpad=15)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        filename = '../figures/visualize_dist_ratios_{}{}.png'.format(model_name, t)\n",
    "        filenames.append(filename)\n",
    "\n",
    "        # More time on first and last frames\n",
    "        if t in [0, n_steps-1]:\n",
    "            for extra_time in range(20):\n",
    "                filenames.append(filename)\n",
    "        # More time at maximum dist_ratios\n",
    "        elif dist_ratios[t-1] == dist_ratios_max:\n",
    "            for extra_time in range(20):\n",
    "                filenames.append(filename)\n",
    "        plt.savefig(filename, dpi=100)\n",
    "        plt.close()\n",
    "        \n",
    "    # Write .gif\n",
    "    gif_name = '../figures/visualize_reconstructed_warping_{}.gif'.format(model_name)\n",
    "    with imageio.get_writer(gif_name, mode='I') as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "    \n",
    "    # remove files\n",
    "    for filename in set(filenames):\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "results_fn = 'rnn.P'\n",
    "rep_name = 'average'\n",
    "model_name = 'RNN'\n",
    "averaged = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "results = load_results(results_fn, rep_name, averaged)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making the .gif and save the results with 'visualize_reconstructed_warping_RNN.gif' filename under the 'figures' folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "build_gif(results, model_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "results_fn = 'rnn.P'\n",
    "rep_name = 'average'\n",
    "model_name = 'RNN_run0'\n",
    "averaged = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "results = load_results(results_fn, rep_name, averaged)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making the .gif and save the results with 'visualize_reconstructed_warping_RNN_run0.gif' filename under the 'figures' folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "build_gif(results, model_name)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "interpreter": {
   "hash": "7048822fac1e221a6e43c543d9991eb664e1bae785bc9fdf9897e223327eed7c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}